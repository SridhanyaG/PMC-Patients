{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9732a5c-f324-42bf-bd7f-0cb92c715c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33556640-b8da-4c34-a92b-65bedcb6153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HUGGINGFACEHUB_API_TOKEN=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\n",
    "!export HF_TOKEN=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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c8015-8a03-4826-a8c1-02c561ead3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "access_token_read = \"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\"\n",
    "access_token_write = \"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\"\n",
    "login(token = access_token_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177db691-31c5-4691-8f53-b3702bb607f7",
   "metadata": {},
   "source": [
    "# For PMC-Patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f64934-9da7-4bb4-a89b-cd1e123d98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import fhirclient.models.patient as fhir_patient\n",
    "import fhirclient.models.condition as fhir_condition\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "from autocorrect import Speller\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from autocorrect import Speller\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa72a0-0b7f-4c78-b5f4-abc41f058c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8066c4f-047e-491a-a825-42c65c8e47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d23ab-8073-47b6-850f-f4c100ac73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "biomodel = HuggingFaceEndpoint(\n",
    "   # repo_id=\"dmis-lab/biobert-v1.1\",\n",
    "    repo_id=\"alvaroalon2/biobert_diseases_ner\",\n",
    "    temperature=0,\n",
    "    model_kwargs={\"max_length\": 180, \"device\": \"cuda\"},\n",
    "    use_auth_token=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72d5ea-eec6-412f-9d49-e0193981a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama(\n",
    "    base_url='http://10.113.8.4:8086',\n",
    "    model=\"cniongolo/biomistral:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a092d91c-d7f4-40f5-921c-ec2b9a19c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"zhengyun21/PMC-Patients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85352519-c071-4e27-980f-2ef8be87fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f273a-7291-4b5e-96c9-e82b2e13464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceeb8e-71f8-4500-bb35-a75e98297f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bee3c-446f-4922-b683-e9dff7e2198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720a069-8c8e-41f9-bf1c-8c165c6c47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13e20c7-1310-43a1-8ef0-35150a0d89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b11bc3-a512-4f15-ba2e-c71f970c7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d19767-c6f7-43c4-88eb-03538848753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bc92c-4c51-4bd7-a50c-521c0489cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "extract_age = lambda x: re.findall(r\"\\d+\\.\\d+\", x)[0]\n",
    "df.age = df.age.apply(extract_age).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd088c8a-d72c-447c-bab8-1354ce40584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8ff355-66a8-4947-a248-8f49f368bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns=[\"file_path\", \"patient_id\", \"patient_uid\", \"relevant_articles\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0464cd2-322f-42d6-a469-0f3f00271a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"\n",
    "The patient is a 45-year-old male with a history of diabetes and hypertension.\n",
    "He was prescribed metformin and lisinopril.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840b205-b21b-41ef-aa6e-d399a0ee0474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\"\n",
    "stop_words  = stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e2b51-aab9-49ff-b267-e89a468dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "\n",
    "    \"\"\"\n",
    "    Converting text to lower case as in, converting \"Hello\" to  \"hello\" or \"HELLO\" to \"hello\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Specll check the words\n",
    "    spell  = Speller(lang='en')\n",
    "    \n",
    "    texts = spell(text)\n",
    "    \n",
    "    return ' '.join([w.lower() for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7298a-1b74-4858-ba98-2b00b2d14697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(lower_case):\n",
    "    # split text phrases into words\n",
    "    words  = nltk.word_tokenize(lower_case)\n",
    "    \n",
    "    \n",
    "    # Create a list of all the punctuations\n",
    "    punctuations = [ '/', '!', '?', ';', ':', '(',')', '[',']', '-', '_', '%']\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    punctuations = re.sub(r'\\W', ' ', str(lower_case))\n",
    "    \n",
    "    # Initialize the stopwords variable, which is a list of words ('and', 'the', 'i', 'yourself', 'is') that do not hold much values as key words\n",
    "    stop_words  = stopwords.words('english')\n",
    "    \n",
    "    # Getting rid of all the words that contain numbers in them\n",
    "    w_num = re.sub('\\w*\\d\\w*', '', lower_case).strip()\n",
    "    \n",
    "    # remove all single characters\n",
    "    lower_case = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', lower_case)\n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    lower_case = re.sub(r'\\s+', ' ', lower_case, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    lower_case = re.sub(r'^b\\s+', '', lower_case)\n",
    "    \n",
    "    # Removing non-english characters\n",
    "    lower_case = re.sub(r'^b\\s+', '', lower_case)\n",
    "    \n",
    "    # Return keywords which are not in stop words \n",
    "    keywords = [word for word in words if not word in stop_words  and word in punctuations and  word in w_num]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d1a9e-2254-4fdd-ae66-88a1fa4905c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14f3b7-2f00-452d-8344-8de6b3f84940",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8a3a6-2f23-484a-b98c-ee7772291282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/home/sridhanya_ganapathi_team_neustar/PMC-Patients/ddata/datasets/NER/BC5CDR-disease/train.tsv\", sep=\"\\t\").fillna(method=\"ffill\")\n",
    "# data['Value'][0] = 'B-Chemical'\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc884e-a14a-4829-9109-a45516cf191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    " \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    " \n",
    "# Load the BioBERT model and tokenizer\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    " \n",
    "# Define the NER pipeline using the BioBERT model\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    " \n",
    "# Example biomedical text\n",
    "text = \"\"\"\n",
    "A 45-year-old male patient was diagnosed with hypertension and prescribed Lisinopril.\n",
    "He also has a history of diabetes and his blood test showed elevated glucose levels.\n",
    "\"\"\"\n",
    "text=clean_text(to_lower(clinical_note))\n",
    "text=\" \".join(text)\n",
    " \n",
    "# Perform Named Entity Recognition (NER) on the text\n",
    "entities = ner_pipeline(text)\n",
    " \n",
    "# Print the detected entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Type: {entity['entity_group']}, Confidence: {entity['score']:.4f}\")\n",
    "#Label_1 typically represents medical text.\n",
    "#Label_0 typically represents non-medical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49da38d8-fa5a-4695-8bad-14eaa91572bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD\" -O biobert_weights && rm -rf /tmp/cookies.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2943e83-48b2-470b-af8d-21b7e2788bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816b441-724e-4145-967b-20fdde4ba3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained('axiong/PMC_LLaMA_13B')\n",
    "model = transformers.LlamaForCausalLM.from_pretrained('axiong/PMC_LLaMA_13B')\n",
    "model.cuda()  # move the model to GPU\n",
    "\n",
    "prompt_input = (\n",
    "    'Below is an instruction that describes a task, paired with an input that provides further context.'\n",
    "    'Write a response that appropriately completes the request.\\n\\n'\n",
    "    '### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:'\n",
    ")\n",
    "\n",
    "example = {\n",
    "    \"instruction\": \"You're a doctor, kindly address the medical queries according to the patient's account. Answer with the best option directly.\",\n",
    "    \"input\": (\n",
    "        \"###Question: A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. \"\n",
    "        \"She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. \"\n",
    "        \"She otherwise feels well and is followed by a doctor for her pregnancy. \"\n",
    "        \"Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air.\"\n",
    "        \"Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. \"\n",
    "        \"Which of the following is the best treatment for this patient?\"\n",
    "        \"###Options: A. Ampicillin B. Ceftriaxone C. Doxycycline D. Nitrofurantoin\"\n",
    "    )\n",
    "}\n",
    "input_str = [prompt_input.format_map(example)]\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    input_str,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    ")\n",
    "print( f\"\\033[32mmodel_inputs\\033[0m: { model_inputs }\" )\n",
    "\n",
    "\n",
    "topk_output = model.generate(\n",
    "    model_inputs.input_ids.cuda(),\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50\n",
    ")\n",
    "output_str = tokenizer.batch_decode(topk_output)\n",
    "print('model predict: ', output_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5346fd8-49f9-49a3-88c5-bb0517509030",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d615c41-e1c3-4f6b-80ec-7aad96547ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "# Load medspacy model\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "text = \"\"\"\n",
    "Past Medical History:\n",
    "1. Atrial fibrillation\n",
    "2. Type II Diabetes Mellitus\n",
    "\n",
    "Assessment and Plan:\n",
    "There is no evidence of pneumonia. Continue warfarin for Afib. Follow up for management of type 2 DM.\n",
    "\"\"\"\n",
    "\n",
    "# Add rules for target concept extraction\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_rules = [\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\"),\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\", pattern=[{\"LOWER\": \"afib\"}]),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"Type II Diabetes Mellitus\", \"PROBLEM\", \n",
    "              pattern=[\n",
    "                  {\"LOWER\": \"type\"},\n",
    "                  {\"LOWER\": {\"IN\": [\"2\", \"ii\", \"two\"]}},\n",
    "                  {\"LOWER\": {\"IN\": [\"dm\", \"diabetes\"]}},\n",
    "                  {\"LOWER\": \"mellitus\", \"OP\": \"?\"}\n",
    "              ]),\n",
    "    TargetRule(\"warfarin\", \"MEDICATION\")\n",
    "]\n",
    "target_matcher.add(target_rules)\n",
    "\n",
    "doc = nlp(text)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021cb77-3ba0-4a4a-a3b7-eb916a9c974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_trf/blob/main/en_core_med7_trf-any-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43476849-2e0b-4fa8-b793-3e4030e53e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "# Load medspacy model\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "text = \"\"\"\n",
    "Past Medical History:\n",
    "1. Atrial fibrillation\n",
    "2. Type II Diabetes Mellitus\n",
    "\n",
    "Assessment and Plan:\n",
    "There is no evidence of pneumonia. Continue warfarin for Afib. Follow up for management of type 2 DM.\n",
    "\"\"\"\n",
    "\n",
    "# Add rules for target concept extraction\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_rules = [\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\"),\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\", pattern=[{\"LOWER\": \"afib\"}]),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"Type II Diabetes Mellitus\", \"PROBLEM\", \n",
    "              pattern=[\n",
    "                  {\"LOWER\": \"type\"},\n",
    "                  {\"LOWER\": {\"IN\": [\"2\", \"ii\", \"two\"]}},\n",
    "                  {\"LOWER\": {\"IN\": [\"dm\", \"diabetes\"]}},\n",
    "                  {\"LOWER\": \"mellitus\", \"OP\": \"?\"}\n",
    "              ]),\n",
    "    TargetRule(\"warfarin\", \"MEDICATION\")\n",
    "]\n",
    "target_matcher.add(target_rules)\n",
    "\n",
    "doc = nlp(text)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e9056-370c-4568-b44a-fe90a49c6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a67ed-c0b4-4ca3-bc8e-389f2dec2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load BioBERT NER model\n",
    "ner_model = pipeline('ner', model='d4data/biomedical-ner-all')\n",
    " \n",
    "# Input text\n",
    "text = \"The patient was diagnosed with glioblastoma and treated with temozolomide.\"\n",
    " \n",
    "# Extract entities\n",
    "entities = ner_model(text)\n",
    " \n",
    "# Output named entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b052eb0-bf32-459e-9288-9edb7b401cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab8290e-c56e-48cc-b68e-a8b30ec6dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c11e8-2c94-42ae-a915-a8cb04799553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "\n",
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0) # pass device=0 if using gpu\n",
    "pipe(\"\"\"The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab1a19e-292e-44b8-8a57-1db3e3e00ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scispacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86adf9d7-d3bc-4f22-b2c7-7a01441ea585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_ner_bc5cdr_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12486b8c-ac6d-4ee2-8cc1-65ffdb84e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_sm-0.5.4.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513e2d2-658e-45f3-9fe9-64ba16c75bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip setuptools wheel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b063b09-37de-4df0-bfd0-7497e3aa7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740f146-3427-4dae-a204-bcc30bb95a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy==2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3172c16-8fb5-471e-ae4b-0c3f84dc3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e880c-ca9f-415e-ace4-e0602153b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bc5cdr_md-0.5.4.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28446952-ed5a-4365-a428-0439eaea0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1bdf0-8b76-43e7-ad10-b10c0978cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "from collections import OrderedDict\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "# Define the text\n",
    "text = \"\"\"\n",
    "The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis. Chart was reviewed, and I will not reiterate her complex history. I am asked to see the patient again because of concerns for coagulopathy. She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now. She is on total parenteral nutrition (TPN) as well. LABORATORY DATA: Labs today showed a white blood cell count of 12,000.\n",
    "\"\"\"\n",
    "\n",
    "# Set up stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize and filter stopwords\n",
    "word_tokens = word_tokenize(text)\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "# Ensure the filtered_sentence list is populated correctly\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w.lower() not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "# Load the UMLS Entity Linker\n",
    "linker = UmlsEntityLinker(k=10, max_entities_per_mention=2)\n",
    "\n",
    "# Register the extension attribute\n",
    "if not Doc.has_extension(\"umls_ents\"):\n",
    "    Doc.set_extension(\"umls_ents\", default=[])\n",
    "\n",
    "# Add the linker to the pipeline\n",
    "nlp.add_pipe(\"scispacy_linker\", last=True)\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract entities\n",
    "entities = doc.ents\n",
    "entity_texts = [str(item) for item in entities]\n",
    "\n",
    "# Create an ordered dictionary of entities\n",
    "entity_dict = OrderedDict.fromkeys(entity_texts)\n",
    "\n",
    "# Process the entities with spaCy\n",
    "entity_doc = nlp(\" \".join(entity_dict.keys()))\n",
    "\n",
    "# Print the entities and their UMLS concepts\n",
    "for entity in entity_doc.ents:\n",
    "    if entity._.umls_ents:  # Check if umls_ents attribute is present\n",
    "        for umls_ent in entity._.umls_ents:\n",
    "            print(\"Entity_name:\", entity.text)\n",
    "            concept_id, score = umls_ent\n",
    "            print(\"concept_id={} Score={}\".format(concept_id, score))\n",
    "    else:\n",
    "        print(f\"No UMLS entities found for: {entity.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d733873-e71e-4c73-9f65-e5cf5c7c148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Register the extension attribute\n",
    "if Doc.has_extension(\"umls_ents\"):\n",
    "    print(\"not\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c0219-911f-4f5f-9c89-bd6d01bd130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739d89d-736c-49f9-91d5-a5477bf023e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99fb38-0100-4173-9e38-0448ece9eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6097652-c458-48ee-b65f-a061ccbfa3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.umls_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b4fd5-2a2a-4e25-ba6c-f299939ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_doc._.umls_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d78bd9-2fa8-438b-ad61-b5803d0515b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_ner_bc5cdr_md-0.5.4.tar.gz\n",
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_trf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a75b96-43e4-4ca6-bd46-fbb17768bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640761d5-e9f4-4731-9386-a6ce96aa8ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9048dd17-42ff-4ea5-8d9d-811d74202a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_sm-0.5.1.tar.gz\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_core_sci_md-0.5.1.tar.gz\n",
    "!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e0d2a-a019-4ef8-85b3-e018908e30a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
