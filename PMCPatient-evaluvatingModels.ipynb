{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9732a5c-f324-42bf-bd7f-0cb92c715c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 20 01:18:12 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   77C    P0              70W /  70W |   9824MiB / 15360MiB |     99%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A   3318075      C   /opt/conda/envs/llm/bin/python              638MiB |\n",
      "|    0   N/A  N/A   3326377      C   /opt/conda/envs/llm/bin/python             9182MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33556640-b8da-4c34-a92b-65bedcb6153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export HUGGINGFACEHUB_API_TOKEN= \n",
    "!export HF_TOKEN= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a464af-ef4a-4097-a443-b72870c35dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluvating various models and final conclusion is fine tuning is best option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0c8015-8a03-4826-a8c1-02c561ead3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "access_token_read = \" \"\n",
    "access_token_write = \" \"\n",
    "login(token = access_token_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177db691-31c5-4691-8f53-b3702bb607f7",
   "metadata": {},
   "source": [
    "# For PMC-Patients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f64934-9da7-4bb4-a89b-cd1e123d98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "import fhirclient.models.patient as fhir_patient\n",
    "import fhirclient.models.condition as fhir_condition\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import warnings\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8066c4f-047e-491a-a825-42c65c8e47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d23ab-8073-47b6-850f-f4c100ac73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "biomodel = HuggingFaceEndpoint(\n",
    "   # repo_id=\"dmis-lab/biobert-v1.1\",\n",
    "    repo_id=\"alvaroalon2/biobert_diseases_ner\",\n",
    "    temperature=0,\n",
    "    model_kwargs={\"max_length\": 180, \"device\": \"cuda\"},\n",
    "    use_auth_token=\"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\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72d5ea-eec6-412f-9d49-e0193981a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = Ollama(\n",
    "    base_url='http://10.113.8.4:8086',\n",
    "    model=\"cniongolo/biomistral:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0464cd2-322f-42d6-a469-0f3f00271a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_note = \"\"\"\n",
    "The patient is a 45-year-old male with a history of diabetes and hypertension.\n",
    "He was prescribed metformin and lisinopril.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e2b51-aab9-49ff-b267-e89a468dd028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(text):\n",
    "\n",
    "    \"\"\"\n",
    "    Converting text to lower case as in, converting \"Hello\" to  \"hello\" or \"HELLO\" to \"hello\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # Specll check the words\n",
    "    spell  = Speller(lang='en')\n",
    "    \n",
    "    texts = spell(text)\n",
    "    \n",
    "    return ' '.join([w.lower() for w in word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7298a-1b74-4858-ba98-2b00b2d14697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(lower_case):\n",
    "    # split text phrases into words\n",
    "    words  = nltk.word_tokenize(lower_case)\n",
    "    \n",
    "    \n",
    "    # Create a list of all the punctuations\n",
    "    punctuations = [ '/', '!', '?', ';', ':', '(',')', '[',']', '-', '_', '%']\n",
    "    \n",
    "    # Remove all the special characters\n",
    "    punctuations = re.sub(r'\\W', ' ', str(lower_case))\n",
    "    \n",
    "    # Initialize the stopwords variable, which is a list of words ('and', 'the', 'i', 'yourself', 'is') that do not hold much values as key words\n",
    "    stop_words  = stopwords.words('english')\n",
    "    \n",
    "    # Getting rid of all the words that contain numbers in them\n",
    "    w_num = re.sub('\\w*\\d\\w*', '', lower_case).strip()\n",
    "    \n",
    "    # remove all single characters\n",
    "    lower_case = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', lower_case)\n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    lower_case = re.sub(r'\\s+', ' ', lower_case, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    lower_case = re.sub(r'^b\\s+', '', lower_case)\n",
    "    \n",
    "    # Removing non-english characters\n",
    "    lower_case = re.sub(r'^b\\s+', '', lower_case)\n",
    "    \n",
    "    # Return keywords which are not in stop words \n",
    "    keywords = [word for word in words if not word in stop_words  and word in punctuations and  word in w_num]\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d1a9e-2254-4fdd-ae66-88a1fa4905c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee14f3b7-2f00-452d-8344-8de6b3f84940",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "print('We will use the GPU:', torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc884e-a14a-4829-9109-a45516cf191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# !pip install transformers\n",
    "# !pip install torch\n",
    " \n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    " \n",
    "# Load the BioBERT model and tokenizer\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    " \n",
    "# Define the NER pipeline using the BioBERT model\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    " \n",
    "# Example biomedical text\n",
    "text = \"\"\"\n",
    "A 45-year-old male patient was diagnosed with hypertension and prescribed Lisinopril.\n",
    "He also has a history of diabetes and his blood test showed elevated glucose levels.\n",
    "\"\"\"\n",
    "text=clean_text(to_lower(clinical_note))\n",
    "text=\" \".join(text)\n",
    " \n",
    "# Perform Named Entity Recognition (NER) on the text\n",
    "entities = ner_pipeline(text)\n",
    " \n",
    "# Print the detected entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Type: {entity['entity_group']}, Confidence: {entity['score']:.4f}\")\n",
    "#Label_1 typically represents medical text.\n",
    "#Label_0 typically represents non-medical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2943e83-48b2-470b-af8d-21b7e2788bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816b441-724e-4145-967b-20fdde4ba3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "tokenizer = transformers.LlamaTokenizer.from_pretrained('axiong/PMC_LLaMA_13B')\n",
    "model = transformers.LlamaForCausalLM.from_pretrained('axiong/PMC_LLaMA_13B')\n",
    "model.cuda()  # move the model to GPU\n",
    "\n",
    "prompt_input = (\n",
    "    'Below is an instruction that describes a task, paired with an input that provides further context.'\n",
    "    'Write a response that appropriately completes the request.\\n\\n'\n",
    "    '### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:'\n",
    ")\n",
    "\n",
    "example = {\n",
    "    \"instruction\": \"You're a doctor, kindly address the medical queries according to the patient's account. Answer with the best option directly.\",\n",
    "    \"input\": (\n",
    "        \"###Question: A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. \"\n",
    "        \"She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. \"\n",
    "        \"She otherwise feels well and is followed by a doctor for her pregnancy. \"\n",
    "        \"Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air.\"\n",
    "        \"Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. \"\n",
    "        \"Which of the following is the best treatment for this patient?\"\n",
    "        \"###Options: A. Ampicillin B. Ceftriaxone C. Doxycycline D. Nitrofurantoin\"\n",
    "    )\n",
    "}\n",
    "input_str = [prompt_input.format_map(example)]\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    input_str,\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    ")\n",
    "print( f\"\\033[32mmodel_inputs\\033[0m: { model_inputs }\" )\n",
    "\n",
    "\n",
    "topk_output = model.generate(\n",
    "    model_inputs.input_ids.cuda(),\n",
    "    max_new_tokens=1000,\n",
    "    top_k=50\n",
    ")\n",
    "output_str = tokenizer.batch_decode(topk_output)\n",
    "print('model predict: ', output_str[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d615c41-e1c3-4f6b-80ec-7aad96547ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "# Load medspacy model\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "text = \"\"\"\n",
    "Past Medical History:\n",
    "1. Atrial fibrillation\n",
    "2. Type II Diabetes Mellitus\n",
    "\n",
    "Assessment and Plan:\n",
    "There is no evidence of pneumonia. Continue warfarin for Afib. Follow up for management of type 2 DM.\n",
    "\"\"\"\n",
    "\n",
    "# Add rules for target concept extraction\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_rules = [\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\"),\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\", pattern=[{\"LOWER\": \"afib\"}]),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"Type II Diabetes Mellitus\", \"PROBLEM\", \n",
    "              pattern=[\n",
    "                  {\"LOWER\": \"type\"},\n",
    "                  {\"LOWER\": {\"IN\": [\"2\", \"ii\", \"two\"]}},\n",
    "                  {\"LOWER\": {\"IN\": [\"dm\", \"diabetes\"]}},\n",
    "                  {\"LOWER\": \"mellitus\", \"OP\": \"?\"}\n",
    "              ]),\n",
    "    TargetRule(\"warfarin\", \"MEDICATION\")\n",
    "]\n",
    "target_matcher.add(target_rules)\n",
    "\n",
    "doc = nlp(text)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021cb77-3ba0-4a4a-a3b7-eb916a9c974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://huggingface.co/kormilitzin/en_core_med7_trf/blob/main/en_core_med7_trf-any-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43476849-2e0b-4fa8-b793-3e4030e53e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "# Load medspacy model\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "text = \"\"\"\n",
    "Past Medical History:\n",
    "1. Atrial fibrillation\n",
    "2. Type II Diabetes Mellitus\n",
    "\n",
    "Assessment and Plan:\n",
    "There is no evidence of pneumonia. Continue warfarin for Afib. Follow up for management of type 2 DM.\n",
    "\"\"\"\n",
    "\n",
    "# Add rules for target concept extraction\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_rules = [\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\"),\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\", pattern=[{\"LOWER\": \"afib\"}]),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"Type II Diabetes Mellitus\", \"PROBLEM\", \n",
    "              pattern=[\n",
    "                  {\"LOWER\": \"type\"},\n",
    "                  {\"LOWER\": {\"IN\": [\"2\", \"ii\", \"two\"]}},\n",
    "                  {\"LOWER\": {\"IN\": [\"dm\", \"diabetes\"]}},\n",
    "                  {\"LOWER\": \"mellitus\", \"OP\": \"?\"}\n",
    "              ]),\n",
    "    TargetRule(\"warfarin\", \"MEDICATION\")\n",
    "]\n",
    "target_matcher.add(target_rules)\n",
    "\n",
    "doc = nlp(text)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a67ed-c0b4-4ca3-bc8e-389f2dec2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load BioBERT NER model\n",
    "ner_model = pipeline('ner', model='d4data/biomedical-ner-all')\n",
    " \n",
    "# Input text\n",
    "text = \"The patient was diagnosed with glioblastoma and treated with temozolomide.\"\n",
    " \n",
    "# Extract entities\n",
    "entities = ner_model(text)\n",
    " \n",
    "# Output named entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c11e8-2c94-42ae-a915-a8cb04799553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"d4data/biomedical-ner-all\")\n",
    "\n",
    "pipe = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", device=0) # pass device=0 if using gpu\n",
    "pipe(\"\"\"The patient reported no recurrence of palpitations at follow-up 6 months after the ablation.\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3172c16-8fb5-471e-ae4b-0c3f84dc3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import srsly\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf1bdf0-8b76-43e7-ad10-b10c0978cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "from collections import OrderedDict\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "\n",
    "# Define the text\n",
    "text = \"\"\"\n",
    "The patient is well known to me for a history of iron-deficiency anemia due to chronic blood loss from colitis. We corrected her hematocrit last year with intravenous (IV) iron. Ultimately, she had a total proctocolectomy done on 03/14/2007 to treat her colitis. Her course has been very complicated since then with needing multiple surgeries for removal of hematoma. This is partly because she was on anticoagulation for a right arm deep venous thrombosis (DVT) she had early this year, complicated by septic phlebitis. Chart was reviewed, and I will not reiterate her complex history. I am asked to see the patient again because of concerns for coagulopathy. She had surgery again last month to evacuate a pelvic hematoma, and was found to have vancomycin resistant enterococcus, for which she is on multiple antibiotics and followed by infectious disease now. She is on total parenteral nutrition (TPN) as well. LABORATORY DATA: Labs today showed a white blood cell count of 12,000.\n",
    "\"\"\"\n",
    "\n",
    "# Set up stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Tokenize and filter stopwords\n",
    "word_tokens = word_tokenize(text)\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "# Ensure the filtered_sentence list is populated correctly\n",
    "filtered_sentence = []\n",
    "for w in word_tokens:\n",
    "    if w.lower() not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "# Load the UMLS Entity Linker\n",
    "linker = UmlsEntityLinker(k=10, max_entities_per_mention=2)\n",
    "\n",
    "# Register the extension attribute\n",
    "if not Doc.has_extension(\"umls_ents\"):\n",
    "    Doc.set_extension(\"umls_ents\", default=[])\n",
    "\n",
    "# Add the linker to the pipeline\n",
    "nlp.add_pipe(\"scispacy_linker\", last=True)\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract entities\n",
    "entities = doc.ents\n",
    "entity_texts = [str(item) for item in entities]\n",
    "\n",
    "# Create an ordered dictionary of entities\n",
    "entity_dict = OrderedDict.fromkeys(entity_texts)\n",
    "\n",
    "# Process the entities with spaCy\n",
    "entity_doc = nlp(\" \".join(entity_dict.keys()))\n",
    "\n",
    "# Print the entities and their UMLS concepts\n",
    "for entity in entity_doc.ents:\n",
    "    if entity._.umls_ents:  # Check if umls_ents attribute is present\n",
    "        for umls_ent in entity._.umls_ents:\n",
    "            print(\"Entity_name:\", entity.text)\n",
    "            concept_id, score = umls_ent\n",
    "            print(\"concept_id={} Score={}\".format(concept_id, score))\n",
    "    else:\n",
    "        print(f\"No UMLS entities found for: {entity.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d733873-e71e-4c73-9f65-e5cf5c7c148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Register the extension attribute\n",
    "if Doc.has_extension(\"umls_ents\"):\n",
    "    print(\"not\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c0219-911f-4f5f-9c89-bd6d01bd130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in entities:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739d89d-736c-49f9-91d5-a5477bf023e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99fb38-0100-4173-9e38-0448ece9eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6097652-c458-48ee-b65f-a061ccbfa3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc._.umls_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b4fd5-2a2a-4e25-ba6c-f299939ea52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_doc._.umls_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e0d2a-a019-4ef8-85b3-e018908e30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"token-classification\", model=\"Clinical-AI-Apollo/Medical-NER\", aggregation_strategy='simple')\n",
    "result = pipe('45 year old woman diagnosed with CAD')\n",
    "\n",
    "\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b2b8b-bdd7-40ab-b50b-91b381e34279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
